# Deep Learning and Practice 2019 Final Project  
For our project, we want to investigate the role of attention and ways to improve performance.  
Our model architecture is inspired by the winner entry of the [2017 VQA challenge](https://visualqa.org/challenge_2017.html) and the paper [Deep Visual-Semantic Alignments for Generating Image Descriptions](https://arxiv.org/abs/1412.2306).  
  
The model of the winner is described by in [Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering](https://arxiv.org/abs/1707.07998) and [Tips and Tricks for Visual Question Answering:
Learnings from the 2017 Challenge](https://arxiv.org/abs/1708.02711).  

## reference
[Attention On Attention](https://github.com/SinghJasdeep/Attention-on-Attention-for-VQA)  
[2017 VAQ Challenge Winner](https://github.com/hengyuan-hu/bottom-up-attention-vqa)  
[2017 VQA Challenge Winner](https://github.com/markdtw/vqa-winner-cvprw-2017)  
[Visual Question Answering latest articles](http://bbs.cvmart.net/articles/391)  
